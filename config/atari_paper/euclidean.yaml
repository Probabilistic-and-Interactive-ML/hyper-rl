# @package _global_

# Choose environment via a selector group (env=atari|minigrid|procgen)
defaults:
  - /experiment: default
  - /manifold: default
  - /value_fn: default
  - /optimizer: default
  - /encoder: default
  - /envs/dqn: atari
  - _self_

env_type: atari

experiment:
  num_threads: 1
  gpu: 0
  wandb_entity: hyper-rl
  wandb_project_name: "Hyperbolic RL - Atari 10M"
  tag: euclidean
  track: true

# Env settings
env_id: PhoenixNoFrameskip-v4
total_timesteps: 10000000

# Optimizer settings
optimizer:
  algorithm: adam
  learning_rate: 1e-4
  adams_eps: 2.5e-5

manifold:
  manifold: euclidean
  curvature: 1.0
  manifold_dtype: float32

# Q-overrides
value_fn:
  forward_pass: HRL_forward
  small_weights: false
  manifold_params_dtype: float32
  clamping_factor: 1.0
  smoothing_factor: 50.0
  # Value loss parameters
  loss_fn: mse
  loss_num_bins: 51
  loss_min_value: -10.0
  loss_max_value: 10.0

# DDQN settings

# Encoder
encoder:
  embedding_dim: 512
  last_layer_tanh: false
  regularization: none
  feature_scaling: none
  scaling_alpha: 0.95

batch_size: 32
buffer_size: 1000000
learning_starts: 80000
train_frequency: 4
target_network_frequency: 1000
tau: 1.0
gamma: 0.99
start_e: 1.0
end_e: 0.01
exploration_fraction: 0.10

log_frequency: 20000
compute_embedding_metrics: false
